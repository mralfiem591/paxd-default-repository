#!/usr/bin/env python3
"""
Vulnerability Issue Creator

This script processes vulnerabilities from the vulnerabilities JSON file and creates
GitHub issues for vulnerabilities that don't already have an associated issue.
"""

import json
import argparse
import os
import sys
from typing import Dict, List, Any, Optional
import requests
import logging
from datetime import datetime

# Read env vars from .env file if it exists
from dotenv import load_dotenv
load_dotenv()

# Set up logging
def setup_logging(debug: bool = False):
    """Set up logging configuration for both console and file output."""
    level = logging.DEBUG if debug else logging.INFO
    
    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Set up root logger
    logger = logging.getLogger()
    logger.setLevel(level)
    
    # Console handler
    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    
    # File handler (for CI/CD artifact collection)
    if not any(isinstance(h, logging.FileHandler) for h in logger.handlers):
        file_handler = logging.FileHandler('vulnerability_issue_creator.log')
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger


class VulnerabilityIssueCreator:
    def __init__(self, github_token: Optional[str], repo_owner: str, repo_name: str, dry_run: bool = False, debug: bool = False):
        """
        Initialize the vulnerability issue creator.
        
        Args:
            github_token: GitHub personal access token
            repo_owner: Repository owner (username or organization)
            repo_name: Repository name
            dry_run: If True, only show what would be done without creating issues
            debug: If True, show detailed comparison information
        """
        self.github_token = github_token
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.dry_run = dry_run
        self.debug = debug
        self.base_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}"
        self.headers = {
            "Authorization": f"token {github_token or ''}",
            "Accept": "application/vnd.github.v3+json",
            "Content-Type": "application/json"
        } if github_token else {}
        
        # Set up logging
        self.logger = setup_logging(debug)
        
        # Log initialization
        self.logger.info(f"Initialized VulnerabilityIssueCreator for {repo_owner}/{repo_name}")
        self.logger.info(f"Dry run mode: {dry_run}, Debug mode: {debug}")

    def load_vulnerabilities(self, file_path: str) -> Dict[str, List[Dict[str, Any]]]:
        """Load vulnerabilities from JSON file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.logger.info(f"Successfully loaded vulnerabilities from {file_path}")
                return data
        except FileNotFoundError:
            self.logger.error(f"Vulnerability file '{file_path}' not found.")
            sys.exit(1)
        except json.JSONDecodeError as e:
            self.logger.error(f"Invalid JSON in vulnerability file: {e}")
            sys.exit(1)

    def get_existing_issues(self) -> List[Dict[str, Any]]:
        """Fetch existing GitHub issues to check for duplicate vulnerability IDs."""
        if self.dry_run:
            print("[DRY RUN] Would fetch existing GitHub issues")
            return []
        
        try:
            all_issues = []
            page = 1
            per_page = 100
            
            while True:
                url = f"{self.base_url}/issues"
                params = {
                    "state": "all",
                    "page": page,
                    "per_page": per_page
                }
                
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()
                
                issues = response.json()
                if not issues:
                    break
                
                all_issues.extend(issues)
                page += 1
            
            return all_issues
        
        except requests.RequestException as e:
            print(f"Error fetching existing issues: {e}")
            sys.exit(1)

    def get_issue_comments(self, issue_number: int) -> List[Dict[str, Any]]:
        """Fetch comments for a specific issue."""
        if self.dry_run:
            print(f"[DRY RUN] Would fetch comments for issue #{issue_number}")
            return []
        
        try:
            all_comments = []
            page = 1
            per_page = 100
            
            while True:
                url = f"{self.base_url}/issues/{issue_number}/comments"
                params = {
                    "page": page,
                    "per_page": per_page
                }
                
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()
                
                comments = response.json()
                if not comments:
                    break
                
                all_comments.extend(comments)
                page += 1
            
            return all_comments
        
        except requests.RequestException as e:
            print(f"Error fetching comments for issue #{issue_number}: {e}")
            return []

    def extract_vulnerability_id_from_title(self, title: str) -> Optional[str]:
        """Extract vulnerability ID (e.g., PAXD-2025-0001) from issue title."""
        import re
        match = re.search(r'PAXD-\d{4}-\d{4}', title)
        return match.group(0) if match else None

    def get_existing_vulnerability_ids(self, issues: List[Dict[str, Any]]) -> set:
        """Extract vulnerability IDs from existing issues."""
        existing_ids = set()
        
        for issue in issues:
            vuln_id = self.extract_vulnerability_id_from_title(issue.get('title', ''))
            if vuln_id:
                existing_ids.add(vuln_id)
        
        return existing_ids

    def get_existing_vulnerability_issues(self, issues: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """Create a mapping of vulnerability IDs to their GitHub issue objects."""
        existing_issues = {}
        
        for issue in issues:
            vuln_id = self.extract_vulnerability_id_from_title(issue.get('title', ''))
            if vuln_id:
                existing_issues[vuln_id] = issue
        
        return existing_issues

    def format_issue_body(self, vulnerability: Dict[str, Any], package_name: str) -> str:
        """Format the GitHub issue body from vulnerability data."""
        description = vulnerability.get('description', 'No description available')
        severity = vulnerability.get('severity', 'Unknown')
        affected_versions = vulnerability.get('affected_versions', 'Unknown')
        vuln_id = vulnerability.get('id', 'Unknown')
        meta = vulnerability.get('meta', {})
        
        # Main content
        body = f"""## Vulnerability Details

**Vulnerability ID:** {vuln_id}
**Package:** {package_name}
**Severity:** {severity}
**Affected Versions:** {affected_versions}

## Description

{description}

## Metadata
"""
        
        # Add metadata (excluding title)
        for key, value in meta.items():
            if key != 'title':
                body += f"- **{key.title()}:** {value}\n"
        
        body += f"\n---\n*Issue created automatically on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} via PaxD VulnerabilityBot*\n---\nYou should **ALWAYS** keep your system safe from vulnerabilities by updating to the latest versions of software. It is recommended you use the vulnerability scanner tool, which will be built-in to PaxD soon, to regularly check for vulnerabilities and ensure your system's security.\nInstall it with `paxd install paxd-vulnscan`, and run it with `paxd-vulnscan`.\n\nPlease stay safe!"
        
        return body

    def get_labels_from_meta(self, meta: Dict[str, Any]) -> List[str]:
        """Generate labels from metadata (excluding title)."""
        labels = ['vulnerability']  # Always add vulnerability label
        
        for key, value in meta.items():
            if key != 'title':
                # Convert value to string and create label
                label = f"{key}:{str(value).lower()}"
                labels.append(label)
        
        return labels

    def normalize_text(self, text: str) -> str:
        """Normalize text by removing extra whitespace and standardizing formatting."""
        if not text:
            return ""
        # Remove extra whitespace, normalize line endings, strip
        return ' '.join(text.replace('\r\n', '\n').replace('\r', '\n').split())

    def normalize_value(self, value: Any) -> str:
        """Normalize values for comparison (handle booleans, case, etc.)."""
        if isinstance(value, bool):
            return str(value)  # This returns 'True' or 'False'
        if isinstance(value, str):
            return value.strip()
        return str(value)

    def extract_vulnerability_data_from_issue(self, issue_body: str) -> Dict[str, str]:
        """Extract vulnerability data from existing GitHub issue body."""
        import re
        
        data = {}
        
        # Extract main fields using more precise regex patterns
        patterns = {
            'severity': r'\*\*Severity:\*\*\s*(.+?)(?=\n|$)',
            'affected_versions': r'\*\*Affected Versions:\*\*\s*(.+?)(?=\n|$)',
            'description': r'## Description\s*\n\s*(.+?)\s*\n\s*## Metadata',
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, issue_body, re.DOTALL)
            if match:
                extracted = match.group(1).strip()
                if key == 'description':
                    # For description, normalize whitespace but preserve structure
                    data[key] = self.normalize_text(extracted)
                else:
                    data[key] = extracted
        
        # Extract metadata with more robust parsing
        # Updated pattern to handle the new footer content
        metadata_section = re.search(r'## Metadata\s*\n(.+?)\n\s*---.*?via PaxD VulnerabilityBot', issue_body, re.DOTALL)
        if metadata_section:
            metadata_text = metadata_section.group(1)
            # Parse metadata lines like "- **Remote:** True" (handle various spacing)
            meta_lines = re.findall(r'-\s*\*\*(.+?):\*\*\s*(.+?)(?=\n|$)', metadata_text)
            for key, value in meta_lines:
                normalized_key = key.strip().lower()
                # Handle common typos/variations
                if normalized_key == 'privelege':
                    normalized_key = 'privilege'
                
                normalized_value = self.normalize_value(value.strip())
                data[f'meta_{normalized_key}'] = normalized_value
        
        return data

    def compare_vulnerability_data(self, current_vuln: Dict[str, Any], existing_issue: Dict[str, Any], package_name: str) -> Optional[Dict[str, Any]]:
        """Compare current vulnerability data with existing issue and return changes."""
        existing_data = self.extract_vulnerability_data_from_issue(existing_issue.get('body', ''))
        
        if self.debug:
            print(f"    [DEBUG] Extracted data from existing issue: {existing_data}")
            print(f"    [DEBUG] Current vulnerability data: {current_vuln}")
        
        changes = {}
        
        # Normalize current data for comparison
        current_severity = str(current_vuln.get('severity', 'Unknown')).strip()
        current_affected_versions = str(current_vuln.get('affected_versions', 'Unknown')).strip()
        current_description = self.normalize_text(current_vuln.get('description', 'No description available'))
        
        # Compare main fields with proper normalization
        existing_severity = existing_data.get('severity', 'Unknown').strip()
        existing_affected_versions = existing_data.get('affected_versions', 'Unknown').strip()
        existing_description = existing_data.get('description', 'No description available')
        
        if existing_severity != current_severity:
            changes['severity'] = {
                'old': existing_severity,
                'new': current_severity
            }
        
        if existing_affected_versions != current_affected_versions:
            changes['affected_versions'] = {
                'old': existing_affected_versions,
                'new': current_affected_versions
            }
        
        if existing_description != current_description:
            changes['description'] = {
                'old': existing_description,
                'new': current_description
            }
        
        # Compare metadata with proper normalization
        current_meta = current_vuln.get('meta', {})
        for key, value in current_meta.items():
            if key == 'title':
                continue
            
            # Handle typos in key names
            normalized_key = key.lower()
            if normalized_key == 'privelege':
                normalized_key = 'privilege'
            
            meta_key = f'meta_{normalized_key}'
            current_value = self.normalize_value(value)
            existing_value = existing_data.get(meta_key, '')
            
            # Handle boolean comparison specifically
            if isinstance(value, bool):
                # Normalize boolean representations
                existing_bool_value = existing_value.lower() in ['true', '1', 'yes', 'on']
                if value != existing_bool_value:
                    changes[f'metadata.{key}'] = {
                        'old': existing_value or 'Not set',
                        'new': current_value
                    }
            else:
                # String comparison (case-insensitive for certain fields)
                if normalized_key in ['complexity', 'privilege', 'privelege', 'vector', 'impact', 'confidentiality', 'integrity']:
                    if existing_value.lower() != current_value.lower():
                        changes[f'metadata.{key}'] = {
                            'old': existing_value or 'Not set',
                            'new': current_value
                        }
                else:
                    if existing_value != current_value:
                        changes[f'metadata.{key}'] = {
                            'old': existing_value or 'Not set',
                            'new': current_value
                        }
        
        return changes if changes else None

    def generate_vulnerability_hash(self, vulnerability: Dict[str, Any]) -> str:
        """Generate a hash representing the current state of vulnerability data."""
        import hashlib
        
        # Create a normalized representation of the vulnerability data
        data_to_hash = {
            'severity': str(vulnerability.get('severity', 'Unknown')).strip(),
            'affected_versions': str(vulnerability.get('affected_versions', 'Unknown')).strip(),
            'description': self.normalize_text(vulnerability.get('description', 'No description available')),
        }
        
        # Add metadata (excluding title)
        meta = vulnerability.get('meta', {})
        for key, value in meta.items():
            if key != 'title':
                data_to_hash[f'meta_{key.lower()}'] = self.normalize_value(value)
        
        # Sort keys for consistent hashing
        sorted_data = sorted(data_to_hash.items())
        data_string = str(sorted_data)
        
        return hashlib.md5(data_string.encode('utf-8')).hexdigest()[:12]

    def has_recent_update_comment(self, issue_number: int, vuln_id: str, current_hash: str) -> bool:
        """Check if there's already an update comment for the current vulnerability state."""
        comments = self.get_issue_comments(issue_number)
        
        for comment in comments:
            body = comment.get('body', '')
            # Check if this is an update comment for this vulnerability
            if f"## ðŸ”„ Vulnerability Update - {vuln_id}" in body:
                # Check if the comment contains a hash matching current state
                if f"Data Hash: {current_hash}" in body:
                    if self.debug:
                        print(f"    [DEBUG] Found matching update comment with hash {current_hash}")
                    return True
        
        return False

    def format_changes_comment(self, changes: Dict[str, Any], vuln_id: str, data_hash: str) -> str:
        """Format a comment showing the changes made to a vulnerability."""
        comment = f"""## ðŸ”„ Vulnerability Update - {vuln_id}

The vulnerability data has been updated. Here are the changes:

"""
        
        for field, change in changes.items():
            field_display = field.replace('_', ' ').replace('metadata.', 'metadata: ').title()
            comment += f"""### {field_display}
- **Previous:** {change['old']}
- **Current:** {change['new']}

"""
        
        comment += f"---\n*Update detected and posted automatically on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} via PaxD VulnerabilityBot*  \n*Data Hash: {data_hash}*"
        
        return comment

    def create_issue_comment(self, issue_number: int, comment_body: str) -> bool:
        """Create a comment on an existing GitHub issue."""
        if self.dry_run:
            print(f"[DRY RUN] Would create comment on issue #{issue_number}:")
            print(f"  Comment preview: {comment_body[:200]}...")
            print()
            return True
        
        try:
            url = f"{self.base_url}/issues/{issue_number}/comments"
            data = {"body": comment_body}
            
            response = requests.post(url, headers=self.headers, json=data)
            response.raise_for_status()
            
            comment_data = response.json()
            print(f"ðŸ’¬ Added comment to issue #{issue_number}: {comment_data['html_url']}")
            return True
        
        except requests.RequestException as e:
            print(f"âŒ Error creating comment on issue #{issue_number}: {e}")
            return False

    def update_issue_title_and_labels(self, issue_number: int, new_title: str, new_labels: List[str]) -> bool:
        """Update an existing GitHub issue's title and labels."""
        if self.dry_run:
            print(f"[DRY RUN] Would update issue #{issue_number}:")
            print(f"  New title: {new_title}")
            print(f"  New labels: {', '.join(new_labels)}")
            print()
            return True
        
        try:
            url = f"{self.base_url}/issues/{issue_number}"
            data = {
                "title": new_title,
                "labels": new_labels
            }
            
            response = requests.patch(url, headers=self.headers, json=data)
            response.raise_for_status()
            
            print(f"ðŸ“ Updated issue #{issue_number} title and labels")
            return True
        
        except requests.RequestException as e:
            print(f"âŒ Error updating issue #{issue_number}: {e}")
            return False

    def create_github_issue(self, title: str, body: str, labels: List[str]) -> bool:
        """Create a GitHub issue."""
        if self.dry_run:
            print(f"[DRY RUN] Would create issue:")
            print(f"  Title: {title}")
            print(f"  Labels: {', '.join(labels)}")
            print(f"  Body preview: {body[:200]}...")
            print()
            return True
        
        try:
            url = f"{self.base_url}/issues"
            data = {
                "title": title,
                "body": body,
                "labels": labels
            }
            
            response = requests.post(url, headers=self.headers, json=data)
            response.raise_for_status()
            
            issue_data = response.json()
            print(f"âœ… Created issue: {issue_data['html_url']}")
            return True
        
        except requests.RequestException as e:
            print(f"âŒ Error creating issue '{title}': {e}")
            return False

    def process_vulnerabilities(self, vulnerabilities_file: str) -> None:
        """Process all vulnerabilities and create GitHub issues as needed."""
        self.logger.info("Starting vulnerability processing...")
        self.logger.info("Loading vulnerabilities...")
        vulnerabilities_data = self.load_vulnerabilities(vulnerabilities_file)
        
        self.logger.info("Fetching existing GitHub issues...")
        existing_issues = self.get_existing_issues()
        existing_vuln_ids = self.get_existing_vulnerability_ids(existing_issues)
        existing_vuln_issues = self.get_existing_vulnerability_issues(existing_issues)
        
        if existing_vuln_ids:
            self.logger.info(f"Found {len(existing_vuln_ids)} existing vulnerability issues: {', '.join(sorted(existing_vuln_ids))}")
        else:
            self.logger.info("No existing vulnerability issues found.")
        
        total_processed = 0
        total_created = 0
        total_skipped = 0
        total_updated = 0
        
        # Process each package's vulnerabilities
        for package_name, vulnerabilities in vulnerabilities_data.items():
            self.logger.info(f"Processing package: {package_name}")
            
            for vulnerability in vulnerabilities:
                vuln_id = vulnerability.get('id')
                if not vuln_id:
                    self.logger.warning(f"Skipping vulnerability without ID in {package_name}")
                    continue
                
                total_processed += 1
                
                # Check if issue already exists
                if vuln_id in existing_vuln_ids:
                    existing_issue = existing_vuln_issues[vuln_id]
                    
                    # Compare vulnerability data for changes
                    changes = self.compare_vulnerability_data(vulnerability, existing_issue, package_name)
                    
                    if changes:
                        # Generate hash for current vulnerability state
                        current_hash = self.generate_vulnerability_hash(vulnerability)
                        
                        # Check if we've already posted an update comment for this state
                        if self.has_recent_update_comment(existing_issue['number'], vuln_id, current_hash):
                            print(f"  â­ï¸  {vuln_id} already has update comment for current state")
                            total_skipped += 1
                        else:
                            print(f"  ðŸ”„ Detected changes in {vuln_id}, posting update comment...")
                            comment_body = self.format_changes_comment(changes, vuln_id, current_hash)
                            
                            # Get title from metadata for the updated title
                            meta = vulnerability.get('meta', {})
                            base_title = meta.get('title', f"Vulnerability {vuln_id}")
                            
                            # Create updated title, avoiding duplicate [UPDATED] tags
                            if "[UPDATED]" not in existing_issue.get('title', ''):
                                updated_title = f"[{vuln_id}] {base_title} [UPDATED]"
                            else:
                                updated_title = existing_issue.get('title', f"[{vuln_id}] {base_title} [UPDATED]")
                            
                            # Get updated labels
                            updated_labels = self.get_labels_from_meta(meta)
                            if 'updated' not in updated_labels:
                                updated_labels.append('updated')  # Add an 'updated' label
                            
                            # Remove duplicates while preserving order
                            updated_labels = list(dict.fromkeys(updated_labels))
                            
                            # Post comment and update issue
                            comment_success = self.create_issue_comment(existing_issue['number'], comment_body)
                            update_success = self.update_issue_title_and_labels(
                                existing_issue['number'], 
                                updated_title, 
                                updated_labels
                            )
                            
                            if comment_success and update_success:
                                total_updated += 1
                    else:
                        print(f"  âœ… {vuln_id} is up to date (no changes detected)")
                        total_skipped += 1
                    continue
                
                # Get title from metadata
                meta = vulnerability.get('meta', {})
                title = meta.get('title')
                if not title:
                    print(f"  âš ï¸  Skipping {vuln_id} (no title in metadata)")
                    continue
                
                # Format issue content
                issue_title = f"[{vuln_id}] {title}"
                issue_body = self.format_issue_body(vulnerability, package_name)
                issue_labels = self.get_labels_from_meta(meta)
                
                # Create the issue
                print(f"  ðŸŽ¯ Creating new issue for {vuln_id}: {title}")
                if self.create_github_issue(issue_title, issue_body, issue_labels):
                    total_created += 1
        
        # Summary
        self.logger.info("Processing complete!")
        self.logger.info(f"Summary:")
        self.logger.info(f"  Total vulnerabilities processed: {total_processed}")
        self.logger.info(f"  New issues created: {total_created}")
        self.logger.info(f"  Existing issues updated: {total_updated}")
        self.logger.info(f"  Issues unchanged: {total_skipped}")
        
        if self.dry_run:
            self.logger.info("This was a dry run - no actual issues were created or updated.")
        
        # Exit with appropriate code for CI/CD
        if total_processed == 0:
            self.logger.warning("No vulnerabilities were processed - this might indicate an issue")
            sys.exit(1)
        elif total_created > 0 or total_updated > 0:
            self.logger.info("Successfully processed vulnerabilities with changes")
            sys.exit(0)
        else:
            self.logger.info("All vulnerabilities are up to date")
            sys.exit(0)


def main():
    parser = argparse.ArgumentParser(
        description="Create GitHub issues for vulnerabilities",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Dry run to see what would be created
  python vulnerability_issue_creator.py --dry-run
  
  # Create issues for real
  python vulnerability_issue_creator.py --token YOUR_TOKEN --owner mralfiem591 --repo paxd
  
  # Use custom vulnerabilities file
  python vulnerability_issue_creator.py --file ./custom_vulnerabilities.json --dry-run

Environment Variables:
  GITHUB_TOKEN: GitHub personal access token (alternative to --token)
  GITHUB_REPO_OWNER: Repository owner (alternative to --owner)
  GITHUB_REPO_NAME: Repository name (alternative to --repo)
        """
    )
    
    parser.add_argument(
        '--token',
        help='GitHub personal access token (or set GITHUB_TOKEN env var)'
    )
    parser.add_argument(
        '--owner',
        default=os.getenv('GITHUB_REPO_OWNER', 'mralfiem591'),
        help='Repository owner (default: mralfiem591)'
    )
    parser.add_argument(
        '--repo',
        default=os.getenv('GITHUB_REPO_NAME', 'paxd'),
        help='Repository name (default: paxd)'
    )
    parser.add_argument(
        '--file',
        default='vulnerabilities',
        help='Path to vulnerabilities JSON file (default: vulnerabilities)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show what would be done without creating issues'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Show detailed comparison information for troubleshooting'
    )
    
    args = parser.parse_args()
    
    # Get GitHub token
    github_token = args.token or os.getenv('GITHUB_TOKEN')
    if not github_token and not args.dry_run:
        print("Error: GitHub token is required. Set GITHUB_TOKEN env var or use --token option.")
        print("For dry run mode, use --dry-run flag.")
        sys.exit(1)
    
    # Create and run the vulnerability issue creator
    creator = VulnerabilityIssueCreator(
        github_token=github_token,
        repo_owner=args.owner,
        repo_name=args.repo,
        dry_run=args.dry_run,
        debug=args.debug
    )
    
    creator.process_vulnerabilities(args.file)


if __name__ == '__main__':
    main()
